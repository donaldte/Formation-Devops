# ðŸ“˜ Cours Complet sur **EFK** et ses Concurrents

## 1. Introduction Ã  la centralisation des logs

Dans les environnements modernes (microservices, containers, Kubernetes), les logs proviennent de multiples sources :

* Conteneurs (Docker, Kubernetes)
* Applications (backend, frontend, batch jobs)
* Infrastructures (serveurs, rÃ©seau, cloud)

Sans solution centralisÃ©e, il devient difficile de :

* **Rechercher** un Ã©vÃ©nement spÃ©cifique
* **CorrÃ©ler** les logs entre services
* **Analyser** la performance ou les incidents
* **Surveiller** la sÃ©curitÃ© (dÃ©tection dâ€™intrusion)

ðŸ“Œ **But dâ€™un stack EFK** : collecter â†’ centraliser â†’ indexer â†’ visualiser.

---

## 2. Quâ€™est-ce que EFK ?

**EFK** = **Elasticsearch + Fluentd + Kibana**
Câ€™est une stack open source populaire pour la gestion centralisÃ©e des logs.

### 2.1 Elasticsearch (E)

* Moteur de recherche distribuÃ© basÃ© sur **Lucene**
* Stocke les logs sous forme de documents JSON indexÃ©s
* Recherche ultra-rapide avec API REST
* Supporte le filtrage, lâ€™agrÃ©gation et la recherche full-text

ðŸ“Œ **Points clÃ©s** :

* Ã‰critures rapides et distribuÃ©es
* Indexation par champs â†’ requÃªtes complexes
* UtilisÃ© aussi pour la recherche de texte, la sÃ©curitÃ© (SIEM), etc.

---

### 2.2 Fluentd (F)

* **Agent de collecte et transformation des logs**
* RÃ©cupÃ¨re les logs de diffÃ©rentes sources (fichiers, sockets, conteneursâ€¦)
* Les formate (JSON, CSV, custom) et les envoie Ã  Elasticsearch (ou autre)
* Extensible avec plus de **500 plugins** (S3, Kafka, MongoDB, etc.)

ðŸ“Œ **RÃ´le clÃ©** : unifier les logs en un format commun (souvent JSON) et les router.

---

### 2.3 Kibana (K)

* Interface graphique pour interroger et visualiser les donnÃ©es dâ€™Elasticsearch
* CrÃ©e des dashboards interactifs
* Filtres par date, service, niveau de log (INFO, ERRORâ€¦)
* UtilisÃ© pour :

  * Debug dâ€™incidents
  * KPIs en temps rÃ©el
  * SÃ©curitÃ© (Elastic SIEM)

---

## 3. SchÃ©ma du fonctionnement EFK

```
[Application / Serveur / Conteneur]
           â†“ (logs)
        [Fluentd]
           â†“
   [Elasticsearch Cluster]
           â†“
        [Kibana UI]
```

---

## 4. Avantages de EFK

âœ… **Open source** (licence Apache)
âœ… Compatible **Kubernetes / Docker**
âœ… Ã‰volutif (scalable horizontalement)
âœ… RequÃªtes puissantes (Elasticsearch Query DSL)
âœ… Personnalisation avec Fluentd

---

## 5. Limites de EFK

âš  **Consommation mÃ©moire importante** (surtout Elasticsearch)
âš  Courbe dâ€™apprentissage pour Elasticsearch DSL
âš  Maintenance lourde si gros volume de logs (besoin dâ€™un cluster robuste)
âš  Fluentd peut avoir une latence sâ€™il est mal configurÃ©

---

## 6. Concurrents de EFK

### 6.1 ELK (Elasticsearch â€“ Logstash â€“ Kibana)

* **Logstash** remplace Fluentd comme collecteur/parseur
* Plus ancien que Fluentd, trÃ¨s riche en plugins
* **DiffÃ©rence clÃ©** : Fluentd est plus lÃ©ger et consomme moins de ressources

---

### 6.2 Loki â€“ Promtail â€“ Grafana

* **Loki** (Grafana Labs) â†’ stockage optimisÃ© pour logs (index minimal)
* **Promtail** â†’ collecte les logs et les envoie Ã  Loki
* **Grafana** â†’ visualisation
* Avantage : faible coÃ»t de stockage
* InconvÃ©nient : pas aussi puissant quâ€™Elasticsearch pour la recherche full-text

---

### 6.3 Graylog

* BasÃ© sur Elasticsearch + MongoDB
* Interface intÃ©grÃ©e pour la recherche et lâ€™alerting
* Moins de dÃ©pendances que EFK
* SimplicitÃ© dâ€™installation mais moins flexible que Kibana

---

### 6.4 Splunk

* **Solution propriÃ©taire** trÃ¨s performante
* Analyse temps rÃ©el, machine learning, alertes avancÃ©es
* CoÃ»t Ã©levÃ© mais fiable pour les entreprises
* IntÃ©grations sÃ©curitÃ© (SIEM)

---

### 6.5 OpenSearch â€“ Fluent Bit â€“ OpenSearch Dashboards

* **OpenSearch** = fork open source dâ€™Elasticsearch aprÃ¨s changement de licence
* **Fluent Bit** = alternative ultra-lÃ©gÃ¨re Ã  Fluentd
* **OpenSearch Dashboards** = fork de Kibana
* Avantage : 100% open source (Apache 2.0)

---

### 6.6 Datadog Logs

* Service SaaS (pas dâ€™installation)
* Collecte, stockage, visualisation, alerting
* Payant Ã  lâ€™usage
* IdÃ©al pour petites Ã©quipes sans gestion dâ€™infrastructure

---

## 7. Comparaison synthÃ©tique

| Stack                | Collecteur    | Stockage              | Visualisation         | Points forts                                 |
| -------------------- | ------------- | --------------------- | --------------------- | -------------------------------------------- |
| **EFK**              | Fluentd       | Elasticsearch         | Kibana                | Open source, scalable, flexible              |
| **ELK**              | Logstash      | Elasticsearch         | Kibana                | Plugins puissants, historique solide         |
| **Loki**             | Promtail      | Loki DB               | Grafana               | Stockage peu coÃ»teux, simple pour Kubernetes |
| **Graylog**          | Graylog Agent | Elasticsearch+MongoDB | Interface intÃ©grÃ©e    | Plus simple que Kibana                       |
| **Splunk**           | Splunk UF     | Splunk Indexer        | Splunk Web            | TrÃ¨s puissant, ML, alertes avancÃ©es          |
| **OpenSearch Stack** | Fluent Bit    | OpenSearch            | OpenSearch Dashboards | 100% open source, Amazon support             |
| **Datadog Logs**     | Agent DD      | SaaS                  | SaaS                  | Pas dâ€™infra Ã  gÃ©rer, monitoring intÃ©grÃ©      |

---

## 8. Bonnes pratiques avec EFK

1. **Limiter la rÃ©tention des logs** (30-90 jours)
2. **Indexer par date** pour Ã©viter la surcharge dâ€™Elasticsearch
3. **Utiliser Fluent Bit** pour les environnements Ã  faible ressources
4. **Mettre en place un cluster Elasticsearch multi-nÅ“uds** pour la haute disponibilitÃ©
5. **Activer lâ€™alerting** dans Kibana ou via ElastAlert
6. **Compresser les logs archivÃ©s** pour rÃ©duire le coÃ»t stockage

---

## 9. Exemple dâ€™utilisation dans Kubernetes

Environnement Kubernetes avec EFK :

* **Fluentd DaemonSet** â†’ collecte les logs de tous les pods
* **Elasticsearch StatefulSet** â†’ stockage et indexation
* **Kibana Deployment** â†’ interface web

YAML de base pour Fluentd DaemonSet :

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
spec:
  selector:
    matchLabels:
      app: fluentd
  template:
    metadata:
      labels:
        app: fluentd
    spec:
      containers:
      - name: fluentd
        image: fluent/fluentd:v1.14
        env:
        - name: FLUENT_ELASTICSEARCH_HOST
          value: "elasticsearch"
        - name: FLUENT_ELASTICSEARCH_PORT
          value: "9200"
```

---

## 10. Conclusion

* **EFK** est un standard open source pour la gestion des logs
* **Choix de la stack** dÃ©pend de :

  * Volume de logs
  * Budget
  * Besoin de recherche full-text
  * Maintenance interne vs SaaS
* Les **concurrents** comme Loki, Graylog, OpenSearch ou Splunk peuvent Ãªtre plus adaptÃ©s selon les cas dâ€™usage.







# ðŸš€ Guide Complet : EFK + Jaeger sur Minikube avec sÃ©curitÃ© Elasticsearch

---

## ðŸ§° PRÃ‰REQUIS

âœ”ï¸ Une instance EC2 (Ubuntu recommandÃ©)
âœ”ï¸ Minikube installÃ© et en cours dâ€™exÃ©cution (`minikube start`)
âœ”ï¸ `kubectl` opÃ©rationnel
âœ”ï¸ `socat` (facultatif)
âœ”ï¸ Ports suivants ouverts dans les rÃ¨gles de sÃ©curitÃ© EC2 :

* 5601 (Kibana)
* 9200 (Elasticsearch via socat ou port-forward)
* 16686 (Jaeger UI)

---

# ðŸ“¦ Ã‰TAPE 1 : CrÃ©er un Namespace dÃ©diÃ© Ã  lâ€™observabilitÃ©

```bash
kubectl create namespace observability
```

> ðŸ§  On isole tous les composants (Elasticsearch, Fluent Bit, Kibana, Jaeger) dans un namespace pour mieux organiser notre cluster.

---

# ðŸ›¢ï¸ Ã‰TAPE 2 : DÃ©ployer Elasticsearch avec mot de passe activÃ©

ðŸ“„ CrÃ©e un fichier `elasticsearch.yaml` :

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch
  namespace: observability
spec:
  serviceName: "elasticsearch"
  replicas: 1
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      labels:
        app: elasticsearch
    spec:
      containers:
      - name: elasticsearch
        image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0
        ports:
        - containerPort: 9200
        env:
        - name: discovery.type
          value: single-node
        - name: xpack.security.enabled
          value: "true"
        - name: ELASTIC_PASSWORD
          value: "MyStrongPassword123"  # ðŸ” Mot de passe de l'utilisateur "elastic"
---
apiVersion: v1
kind: Service
metadata:
  name: elasticsearch
  namespace: observability
spec:
  ports:
  - port: 9200
    name: http
  selector:
    app: elasticsearch
```

ðŸ› ï¸ Applique le manifest :

```bash
kubectl apply -f elasticsearch.yaml
```

---

# ðŸ–¥ï¸ Ã‰TAPE 3 : DÃ©ployer Kibana et le connecter Ã  Elasticsearch sÃ©curisÃ©

ðŸ“„ CrÃ©e un fichier `kibana.yaml` :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kibana
  namespace: observability
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kibana
  template:
    metadata:
      labels:
        app: kibana
    spec:
      containers:
      - name: kibana
        image: docker.elastic.co/kibana/kibana:7.17.0
        ports:
        - containerPort: 5601
        env:
        - name: ELASTICSEARCH_HOSTS
          value: "http://elastic:MyStrongPassword123@elasticsearch.observability.svc.cluster.local:9200"
---
apiVersion: v1
kind: Service
metadata:
  name: kibana
  namespace: observability
spec:
  ports:
  - port: 5601
    name: http
  selector:
    app: kibana
```

ðŸ› ï¸ Applique :

```bash
kubectl apply -f kibana.yaml
```

---

# ðŸ” Ã‰TAPE 4 : DÃ©ployer Fluent Bit avec authentification vers Elasticsearch

ðŸ“„ CrÃ©e le fichier `fluent-bit-configmap.yaml` :

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-config
  namespace: observability
data:
  fluent-bit.conf: |
    [SERVICE]
        Flush        1
        Daemon       Off
        Log_Level    info
        Parsers_File parsers.conf

    [INPUT]
        Name              tail
        Path              /var/log/containers/*.log
        Parser            docker
        Tag               kube.*
        Refresh_Interval  5
        Skip_Long_Lines  On

    [FILTER]
        Name                kubernetes
        Match               kube.*
        Kube_URL            https://kubernetes.default.svc:443
        Merge_Log           On
        Keep_Log            Off
        K8S-Logging.Parser  On
        K8S-Logging.Exclude On

    [OUTPUT]
        Name  es
        Match *
        Host  elasticsearch.observability.svc.cluster.local
        Port  9200
        HTTP_User  elastic
        HTTP_Passwd  MyStrongPassword123
        Index  fluent-bit
        Type  _doc
        Logstash_Format On
```

ðŸ“„ CrÃ©e maintenant le DaemonSet `fluent-bit-daemonset.yaml` :

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluent-bit
  namespace: observability
spec:
  selector:
    matchLabels:
      name: fluent-bit
  template:
    metadata:
      labels:
        name: fluent-bit
    spec:
      containers:
      - name: fluent-bit
        image: fluent/fluent-bit:1.9
        volumeMounts:
          - name: varlog
            mountPath: /var/log
          - name: config
            mountPath: /fluent-bit/etc/
      volumes:
        - name: varlog
          hostPath:
            path: /var/log
        - name: config
          configMap:
            name: fluent-bit-config
```

ðŸ› ï¸ Applique les deux manifests :

```bash
kubectl apply -f fluent-bit-configmap.yaml
kubectl apply -f fluent-bit-daemonset.yaml
```

---

# ðŸ”­ Ã‰TAPE 5 : DÃ©ployer Jaeger pour les traces distribuÃ©es

```bash
kubectl create -f https://github.com/jaegertracing/jaeger-operator/releases/download/v1.46.0/jaeger-operator.yaml -n observability
```

ðŸ“„ CrÃ©e ensuite le fichier `jaeger.yaml` :

```yaml
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: simplest
  namespace: observability
```

```bash
kubectl apply -f jaeger.yaml
```

---

# ðŸŒ Ã‰TAPE 6 : AccÃ©der aux Interfaces Web (URL des services)

Voici les commandes pour accÃ©der Ã  chaque service en local ou connaÃ®tre leur IP/port si tu exposes via NodePort.

---

### ðŸ”— Voir les services dÃ©ployÃ©s :

```bash
kubectl get svc -n observability
```

ðŸ” Tu verras une sortie comme :

```
NAME             TYPE        CLUSTER-IP       PORT(S)          AGE
elasticsearch    ClusterIP   10.96.0.1        9200/TCP         5m
kibana           ClusterIP   10.96.0.2        5601/TCP         5m
simplest-query   ClusterIP   10.96.0.3        16686/TCP        3m
```

---

### ðŸŒ AccÃ¨s local (avec port-forward)

#### Kibana :

```bash
kubectl port-forward svc/kibana 5601:5601 -n observability
```

> Ouvre [http://localhost:5601](http://localhost:5601)
> Identifiants : `elastic / MyStrongPassword123`

#### Elasticsearch :

```bash
kubectl port-forward svc/elasticsearch 9200:9200 -n observability
```

> Test :

```bash
curl -u elastic:MyStrongPassword123 http://localhost:9200
```

#### Jaeger UI :

```bash
kubectl port-forward svc/simplest-query 16686:16686 -n observability
```

> Ouvre [http://localhost:16686](http://localhost:16686)

---

# âœ… RÃ‰SULTAT ATTENDU

| Composant         | AccÃ¨s via port-forward                           | Description                                    |
| ----------------- | ------------------------------------------------ | ---------------------------------------------- |
| **Elasticsearch** | [http://localhost:9200](http://localhost:9200)   | Base de donnÃ©es des logs (mot de passe requis) |
| **Kibana**        | [http://localhost:5601](http://localhost:5601)   | Interface Web pour visualiser les logs         |
| **Jaeger UI**     | [http://localhost:16686](http://localhost:16686) | Suivi des requÃªtes distribuÃ©es (spans, traces) |

